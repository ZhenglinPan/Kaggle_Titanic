{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This is the refined-version of `feature_engineering_detailed.ipynb`, for more detailed analysis of data, check out the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from feature_creation import cate_colName, Group_Statistics, Target_Encode\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "data_train = pd.read_csv('../../data/train.csv')\n",
    "data_test = pd.read_csv('../../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_cols = ['Pclass', 'Sex', 'SibSp', 'Parch',\n",
    "                'Embarked', 'Cabin']\n",
    "\n",
    "numeric_cols = ['Age', 'Fare']\n",
    "\n",
    "target = 'Survived'\n",
    "\n",
    "discard_cols = ['PassengerId', 'Ticket', 'Name']\n",
    "\n",
    "assert len(category_cols) + len(numeric_cols) + len(discard_cols) + 1 == data_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Cabin' in category_cols: category_cols.remove('Cabin')\n",
    "discard_cols.append('Cabin')\n",
    "\n",
    "data_train['Sex'].replace(to_replace='female', value=0, inplace=True)\n",
    "data_train['Sex'].replace(to_replace='male',  value=1, inplace=True)\n",
    "\n",
    "data_test['Sex'].replace(to_replace='female', value=0, inplace=True)\n",
    "data_test['Sex'].replace(to_replace='male',  value=1, inplace=True)\n",
    "\n",
    "data_train['Embarked'].replace(to_replace='C', value=0, inplace=True)\n",
    "data_train['Embarked'].replace(to_replace='Q',  value=1, inplace=True)\n",
    "data_train['Embarked'].replace(to_replace='S',  value=2, inplace=True)\n",
    "\n",
    "data_test['Embarked'].replace(to_replace='C', value=0, inplace=True)\n",
    "data_test['Embarked'].replace(to_replace='Q',  value=1, inplace=True)\n",
    "data_test['Embarked'].replace(to_replace='S',  value=2, inplace=True)\n",
    "\n",
    "features_train = data_train.drop(columns=discard_cols + [target]).copy()\n",
    "features_test = data_test.drop(columns=discard_cols).copy()\n",
    "labels = data_train[target].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_67996\\2099680929.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dummy_features_train['Age'][i] = dummy_features_train['Age'][j]\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_67996\\2099680929.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dummy_features_test['Age'][i] = dummy_features_train['Pclass'][dummy_features_train.shape[0]-1]\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_67996\\2099680929.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dummy_features_test['Age'][i] = dummy_features_train['Pclass'][j]\n"
     ]
    }
   ],
   "source": [
    "features_train['Age'] = pd.cut(np.array(features_train['Age']), bins=5).codes\n",
    "intervals = pd.cut(np.array(features_train['Age']), bins=5).categories\n",
    "features_test['Age'] = pd.cut(np.array(features_test['Age']), bins=intervals).codes\n",
    "\n",
    "dummy_features_train = features_train.copy()\n",
    "dummy_features_test = features_train.copy()\n",
    "\n",
    "# fill missing value on training data\n",
    "dummy_features_train.sort_values('Pclass', ascending=False, inplace=True)\n",
    "\n",
    "for i in range(dummy_features_train.shape[0]):\n",
    "    if i == 0 and dummy_features_train['Age'][i] == -1:\n",
    "        for j in range(i, dummy_features_train.shape[0]):\n",
    "            if dummy_features_train['Age'][j] != -1:\n",
    "                dummy_features_train['Age'][i] = dummy_features_train['Age'][j]\n",
    "                break\n",
    "    if dummy_features_train['Age'][i] == -1:\n",
    "        for j in range(i, -1, -1):\n",
    "            if dummy_features_train['Age'][j] != -1:\n",
    "                dummy_features_train['Age'][i] = dummy_features_train['Age'][j]\n",
    "                break\n",
    "\n",
    "# apply training filling to test sample(one by one)\n",
    "for i in range(features_test.shape[0]):\n",
    "    if dummy_features_test['Age'][i] == -1:\n",
    "        approx_key = dummy_features_test['Pclass'][i]   # get its pclass as \"approximate key\"\n",
    "        dummy_features_test['Age'][i] = dummy_features_train['Pclass'][dummy_features_train.shape[0]-1]\n",
    "        for j in range(features_train.shape[0]):        # and fill 'Age' in test set with data from training set\n",
    "            if dummy_features_train['Pclass'][j] == approx_key:\n",
    "                dummy_features_test['Age'][i] = dummy_features_train['Pclass'][j]                   \n",
    "\n",
    "# change training feature order back\n",
    "dummy_features_train_reset = dummy_features_train.reset_index()\n",
    "dummy_features_train_reset.sort_values('index', ascending=True, inplace=True)\n",
    "dummy_features_train_reset = dummy_features_train_reset.drop(columns='index')\n",
    "dummy_features_train = dummy_features_train_reset.reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set: fill all rest empties\n",
    "for j in range(dummy_features_train.shape[1]):\n",
    "    for i in range(dummy_features_train.shape[0]):\n",
    "        if np.isnan(dummy_features_train.iloc[i, j]):\n",
    "            dummy_features_train.iloc[i, j] = dummy_features_train.iloc[:, j].mode()\n",
    "\n",
    "# test set: fill all rest empties with training set\n",
    "for j in range(dummy_features_test.shape[1]):\n",
    "    for i in range(dummy_features_test.shape[0]):\n",
    "        if np.isnan(dummy_features_test.iloc[i, j]):\n",
    "            dummy_features_test.iloc[i, j] = dummy_features_train.iloc[:, j].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_features_train.to_csv('../../data/X_train_process_checkpoint0.csv', index=False)\n",
    "dummy_features_test.to_csv('../../data/X_test_process_checkpoint0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = pd.read_csv(\"../../data/X_train_process_checkpoint0.csv\")\n",
    "features_test = pd.read_csv(\"../../data/X_test_process_checkpoint0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python310\\lib\\site-packages\\sklearn\\metrics\\cluster\\_supervised.py:64: UserWarning: Clustering metrics expects discrete values but received continuous values for label, and binary values for target\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "colNames = list(features_train.columns)    \n",
    "colNames.remove(\"Fare\")     # Fare is continuous, remove it\n",
    "\n",
    "colNames_new_l = []\n",
    "features_train_new_l = []   # new list\n",
    "features_test_new_l = []   # new list\n",
    "\n",
    "for col_index, col_name in enumerate(colNames):\n",
    "    for col_sub_index in range(col_index+1, len(colNames)):\n",
    "        newNames = col_name + '&' + colNames[col_sub_index]\n",
    "\n",
    "for col_index, col_name in enumerate(colNames):\n",
    "    for col_sub_index in range(col_index+1, len(colNames)):\n",
    "        newNames = col_name + '&' + colNames[col_sub_index]\n",
    "        colNames_new_l.append(newNames)\n",
    "        newDF_train = pd.Series(features_train[col_name].astype('str') \n",
    "                          + '&'\n",
    "                          + features_train[colNames[col_sub_index]].astype('str'), \n",
    "                          name=col_name)\n",
    "        newDF_test = pd.Series(features_test[col_name].astype('str') \n",
    "                          + '&'\n",
    "                          + features_test[colNames[col_sub_index]].astype('str'), \n",
    "                          name=col_name)\n",
    "        features_train_new_l.append(newDF_train)\n",
    "        features_test_new_l.append(newDF_test)\n",
    "\n",
    "features_train_new = pd.concat(features_train_new_l, axis=1)\n",
    "features_test_new = pd.concat(features_test_new_l, axis=1)\n",
    "features_train_new.columns = colNames_new_l\n",
    "features_test_new.columns = colNames_new_l\n",
    "\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit_transform(features_train_new)\n",
    "\n",
    "cate_colName(enc, colNames_new_l, drop=None)\n",
    "features_train_new_af = pd.DataFrame(enc.fit_transform(features_train_new).toarray(), \n",
    "                               columns = cate_colName(enc, colNames_new_l, drop=None))\n",
    "features_test_new_af = pd.DataFrame(enc.fit_transform(features_test_new).toarray(), \n",
    "                               columns = cate_colName(enc, colNames_new_l, drop=None))\n",
    "features_train_temp = pd.concat([features_train, features_train_new_af], axis=1)\n",
    "features_test_temp = pd.concat([features_test, features_test_new_af], axis=1)\n",
    "\n",
    "# only train set goes to filtering to obtain column names\n",
    "sel = VarianceThreshold()\n",
    "sel.fit(features_train_temp)\n",
    "CrossComb_cols = features_train_temp.columns[sel.variances_ > 0.01 * 0.99]\n",
    "\n",
    "chi2_p = chi2(features_train_temp[CrossComb_cols], labels)[1]\n",
    "chi2_CrossComb_cols = []\n",
    "for pValue, colname in zip(chi2_p, CrossComb_cols):\n",
    "    if pValue < 0.01:\n",
    "        chi2_CrossComb_cols.append(colname)\n",
    "\n",
    "MI = mutual_info_classif(features_train_temp[CrossComb_cols], labels, discrete_features=True, random_state=22)\n",
    "MI_threshold = MI.mean() * 0.1\n",
    "MI_CrossComb_cols = []\n",
    "for MIvalue, colname in zip(MI, CrossComb_cols):\n",
    "    if MIvalue > MI_threshold:\n",
    "        MI_CrossComb_cols.append(colname)\n",
    "\n",
    "CrossComb_cols_select = list(set(chi2_CrossComb_cols) & set(MI_CrossComb_cols))\n",
    "\n",
    "# apply selected column names to test data\n",
    "features_train_temp_cb = features_train_temp[CrossComb_cols_select]\n",
    "features_test_temp_cb = features_test_temp[CrossComb_cols_select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_temp_cb.to_csv('../../data/X_train_process_checkpoint1.csv', index=False)\n",
    "features_test_temp_cb.to_csv('../../data/X_test_process_checkpoint1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_67996\\3934594605.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df_test.iloc[i, j] = temp_df_train.iloc[:, j].mode()\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_67996\\3934594605.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df_test.iloc[i, j] = temp_df_train.iloc[:, j].mode()\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_67996\\3934594605.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df_test.iloc[i, j] = temp_df_train.iloc[:, j].mode()\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_67996\\3934594605.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df_test.iloc[i, j] = temp_df_train.iloc[:, j].mode()\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_67996\\3934594605.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df_test.iloc[i, j] = temp_df_train.iloc[:, j].mode()\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_67996\\3934594605.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df_test.iloc[i, j] = temp_df_train.iloc[:, j].mode()\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_67996\\3934594605.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df_test.iloc[i, j] = temp_df_train.iloc[:, j].mode()\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_67996\\3934594605.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  temp_df_test.iloc[i, j] = temp_df_train.iloc[:, j].mode()\n"
     ]
    }
   ],
   "source": [
    "ord_enc = OrdinalEncoder()\n",
    "ord_enc.fit(features_train[category_cols])\n",
    "\n",
    "X_train_OE = pd.DataFrame(ord_enc.transform(features_train[category_cols]), columns=category_cols)\n",
    "X_train_OE.index = features_train.index\n",
    "X_train_OE = pd.concat([X_train_OE, features_train[numeric_cols]], axis=1)\n",
    "\n",
    "X_test_OE = pd.DataFrame(ord_enc.transform(features_test[category_cols]), columns=category_cols)\n",
    "X_test_OE.index = features_test.index\n",
    "X_test_OE = pd.concat([X_test_OE, features_test[numeric_cols]], axis=1)\n",
    "\n",
    "# obtain key cols on training set\n",
    "chi2_p = chi2(X_train_OE[category_cols], labels)[1]\n",
    "chi2_select_cols = []\n",
    "for pValue, colname in zip(chi2_p, category_cols):\n",
    "    if pValue < 0.01: chi2_select_cols.append(colname)\n",
    "\n",
    "MI = mutual_info_classif(X_train_OE[category_cols], labels, discrete_features=True, random_state=22)\n",
    "MI_select_cols = []\n",
    "MI_threshold = MI.mean() * 0.1\n",
    "for MIvalue, colname in zip(MI, category_cols):\n",
    "    if MIvalue > MI_threshold: MI_select_cols.append(colname)\n",
    "\n",
    "keycols = list(set(chi2_select_cols) & set(MI_select_cols))\n",
    "cat_rest = []   # categorical variables that are not keyCols\n",
    "for col in category_cols:\n",
    "    if col not in keycols: cat_rest.append(col)\n",
    "\n",
    "col_temp = keycols.copy()\n",
    "GroupStat_train = pd.DataFrame()\n",
    "GroupStat_test = pd.DataFrame()\n",
    "\n",
    "# apply key cols to test set\n",
    "for i in range(len(col_temp)):\n",
    "    keyCol = col_temp.pop(i)\n",
    "    gp_features_train_new, gp_features_test_new, gp_colNames_train_new, gp_colNames_test_new = \\\n",
    "        Group_Statistics(keyCol, X_train_OE, X_test_OE, numeric_cols, col_temp+cat_rest)\n",
    "    \n",
    "    GroupStat_train = pd.concat([GroupStat_train, gp_features_train_new], axis=1)\n",
    "    GroupStat_test = pd.concat([GroupStat_test, gp_features_test_new], axis=1)\n",
    "\n",
    "    col_temp = keycols.copy()\n",
    "\n",
    "# obtain GroupStat_cols_select on training set\n",
    "sel = VarianceThreshold()\n",
    "sel.fit(GroupStat_train)\n",
    "\n",
    "GroupStat_cols = list(GroupStat_train.columns[sel.variances_ > 0])\n",
    "temp_df_train = GroupStat_train[GroupStat_cols]\n",
    "temp_df_test = GroupStat_test[GroupStat_cols]\n",
    "\n",
    "for j in range(temp_df_train.shape[1]):\n",
    "    for i in range(temp_df_train.shape[0]):\n",
    "        if np.isnan(temp_df_train.iloc[i, j]):\n",
    "            temp_df_train.iloc[i, j] = temp_df_train.iloc[:, j].mode()\n",
    "\n",
    "for j in range(temp_df_test.shape[1]):\n",
    "    for i in range(temp_df_test.shape[0]):\n",
    "        if np.isnan(temp_df_test.iloc[i, j]):\n",
    "            temp_df_test.iloc[i, j] = temp_df_train.iloc[:, j].mode()\n",
    "\n",
    "f_classif_p = f_classif(temp_df_train, labels)[1]\n",
    "f_classif_GroupStat_cols = []\n",
    "for pValue, colname in zip(f_classif_p, GroupStat_cols):\n",
    "    if pValue < 0.01:\n",
    "        f_classif_GroupStat_cols.append(colname)\n",
    "        \n",
    "MI = mutual_info_classif(temp_df_train, labels, random_state=22)\n",
    "MI_threshold = MI.mean() * 0.1\n",
    "MI_GroupStat_cols = []\n",
    "for MIvalue, colname in zip(MI, GroupStat_cols):\n",
    "    if MIvalue > MI_threshold:\n",
    "        MI_GroupStat_cols.append(colname)\n",
    "\n",
    "\n",
    "GroupStat_cols_select = list(set(f_classif_GroupStat_cols) & set(MI_GroupStat_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df_train[GroupStat_cols_select].to_csv('../../data/X_train_process_checkpoint2.csv', index=False)\n",
    "temp_df_test[GroupStat_cols_select].to_csv('../../data/X_test_process_checkpoint2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = features_test\n",
    "\n",
    "X_test_OE = pd.DataFrame(ord_enc.transform(X_test[category_cols]), columns=category_cols)\n",
    "X_test_OE.index = X_test.index\n",
    "X_test_OE = pd.concat([X_test_OE, X_test[numeric_cols]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_67996\\4162411097.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  TarEnc_train_temp.iloc[i, j] = temp_df_train.iloc[:, j].mean()\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_67996\\4162411097.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  TarEnc_test_temp.iloc[i, j] = temp_df_train.iloc[:, j].mean()\n"
     ]
    }
   ],
   "source": [
    "col_cat = [target]\n",
    "\n",
    "col_temp = category_cols.copy()\n",
    "TarEnc_train = pd.DataFrame()\n",
    "TarEnc_test = pd.DataFrame()\n",
    "\n",
    "for keyCol in col_temp:\n",
    "    features_train1, features_test1, colNames_train_new, colNames_test_new = Target_Encode(keyCol, \n",
    "                                                                                           X_train_OE, \n",
    "                                                                                           labels,\n",
    "                                                                                           X_test_OE, \n",
    "                                                                                           col_cat=col_cat, \n",
    "                                                                                           extension=True)\n",
    "    \n",
    "    TarEnc_train = pd.concat([TarEnc_train, features_train1],axis=1)\n",
    "    TarEnc_test = pd.concat([TarEnc_test, features_test1],axis=1)\n",
    "    \n",
    "    col_temp = category_cols.copy()\n",
    "\n",
    "sel = VarianceThreshold()\n",
    "sel.fit(TarEnc_train)\n",
    "TarEnc_cols = list(TarEnc_train.columns[sel.variances_ > 0])\n",
    "TarEnc_train_temp = TarEnc_train[TarEnc_cols]\n",
    "TarEnc_test_temp = TarEnc_test[TarEnc_cols]\n",
    "\n",
    "for j in range(TarEnc_train_temp.shape[1]):\n",
    "    for i in range(TarEnc_train_temp.shape[0]):\n",
    "        if np.isnan(TarEnc_train_temp.iloc[i, j]):\n",
    "            TarEnc_train_temp.iloc[i, j] = temp_df_train.iloc[:, j].mean()\n",
    "\n",
    "for j in range(TarEnc_test_temp.shape[1]):\n",
    "    for i in range(TarEnc_test_temp.shape[0]):\n",
    "        if np.isnan(TarEnc_test_temp.iloc[i, j]):\n",
    "            TarEnc_test_temp.iloc[i, j] = temp_df_train.iloc[:, j].mean()\n",
    "            \n",
    "f_classif_p = f_classif(TarEnc_train_temp, labels)[1]\n",
    "f_classif_TarEnc_cols = []\n",
    "for pValue, colname in zip(f_classif_p, TarEnc_cols):\n",
    "    if pValue < 0.01:\n",
    "        f_classif_TarEnc_cols.append(colname)\n",
    "        \n",
    "MI = mutual_info_classif(TarEnc_train_temp, labels, random_state=22)\n",
    "MI_threshold = MI.mean() * 0.01\n",
    "MI_TarEnc_cols = []\n",
    "for MIvalue, colname in zip(MI, TarEnc_cols):\n",
    "    if MIvalue > MI_threshold: MI_TarEnc_cols.append(colname)\n",
    "\n",
    "TarEnc_cols_select = list(set(f_classif_TarEnc_cols) & set(MI_TarEnc_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TarEnc_train[TarEnc_cols_select].to_csv(\"../../data/X_train_process_checkpoint3.csv\", index = False)\n",
    "TarEnc_test[TarEnc_cols_select].to_csv(\"../../data/X_test_process_checkpoint3.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target encoding might lead to overfitting\n",
    "# so if it happens, turn it off \n",
    "target_encoding_flag = True\n",
    "\n",
    "labels = pd.read_csv(\"../../data/train.csv\")[\"Survived\"]\n",
    "df0 = pd.read_csv(\"../../data/X_train_process_checkpoint0.csv\")\n",
    "df1 = pd.read_csv(\"../../data/X_train_process_checkpoint1.csv\")\n",
    "df2 = pd.read_csv(\"../../data/X_train_process_checkpoint2.csv\")\n",
    "if(target_encoding_flag):\n",
    "    df3 = pd.read_csv(\"../../data/X_train_process_checkpoint3.csv\")\n",
    "    features_final = pd.concat([labels, df0, df1, df2, df3], axis = 1)\n",
    "else:\n",
    "    features_final = pd.concat([labels, df0, df1, df2], axis = 1)\n",
    "\n",
    "features_final.to_csv(\"../../data/train_new.csv\", index=False)\n",
    "\n",
    "df0 = pd.read_csv(\"../../data/X_test_process_checkpoint0.csv\")\n",
    "df1 = pd.read_csv(\"../../data/X_test_process_checkpoint1.csv\")\n",
    "df2 = pd.read_csv(\"../../data/X_test_process_checkpoint2.csv\")\n",
    "if target_encoding_flag is True:\n",
    "    df3 = pd.read_csv(\"../../data/X_test_process_checkpoint3.csv\")\n",
    "    features_final = pd.concat([df0, df1, df2, df3], axis = 1)\n",
    "else:\n",
    "    features_final = pd.concat([df0, df1, df2], axis = 1)\n",
    "\n",
    "features_final.to_csv(\"../../data/test_new.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
